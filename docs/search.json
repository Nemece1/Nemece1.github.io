[
  {
    "objectID": "wisconsin_districts.html",
    "href": "wisconsin_districts.html",
    "title": "Congressional Districs of Wisconsin",
    "section": "",
    "text": "Wisconsin’s susceptibility to gerrymandering arises from its identity as a swing state characterized by contested elections. The state’s distinct urban-rural disparity offers fertile ground for biased manipulation of electoral boundaries, prompting concerns regarding equal representation. To show these suspicions, we have leveraged data sourced from congressional district shape files for the 113th Congress, obtained from a UCLA website, and overlaid them onto the geographical borders of Wisconsin’s congressional districts. The table below provides a breakdown of the eight congressional districts alongside the respective percentages of Republican voters in each district.\n\n\n\n\n\ndistrict\nr_prop\nwinner\n\n\n\n\n5\n0.6676090\nRepublican\n\n\n1\n0.6499393\nRepublican\n\n\n8\n0.6268105\nRepublican\n\n\n7\n0.6170728\nRepublican\n\n\n6\n0.5719445\nRepublican\n\n\n2\n0.3119968\nDemocrat\n\n\n3\n0.0000000\nDemocrat\n\n\n4\n0.0000000\nDemocrat\n\n\n\n\n\nWe observe a trend where Republican districts secure victories by narrow margins, contrasting with Democratic districts that either lack Republican voters entirely or win their districts uncontested. This suggests a potential instance of gerrymandering, where the state is strategically divided, concentrating Democratic voters into a single area to account for only one electoral representative, while Republicans dominate the majority of other districts.\nThese plots show the political party of each winning district as well as their shape and size relative to the state as well as the other districts.\n\n\nWarning in st_point_on_surface.sfc(sf::st_zm(x)): st_point_on_surface may not\ngive correct results for longitude/latitude data"
  },
  {
    "objectID": "Projectsland.html",
    "href": "Projectsland.html",
    "title": "Projects",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nUnderstanding Medications: Uncovering Side Effects\n\n\n\n\n\n\n\nMedicine\n\n\nData Science\n\n\n\n\nLance Nemecek and Jackson Marsh\n\n\n\n\n \n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Lance Nemecek",
    "section": "",
    "text": "Student of Mathematics and Data Science  MSCS Department @ St. Olaf College\n\n\nHigh school Degree | Mound Westonka High School\nIn progress: BA in Math with Stats and Data Science concentration 2026 | St. Olaf College\n\n\n\nServer | Woodhill Country Club\nMetal Fabricator | Industrial Louvers\nFood Expoditor | Maynards Restaurant"
  },
  {
    "objectID": "index.html#lance-nemecek",
    "href": "index.html#lance-nemecek",
    "title": "Lance Nemecek",
    "section": "",
    "text": "Student of Mathematics and Data Science  MSCS Department @ St. Olaf College\n\n\nHigh school Degree | Mound Westonka High School\nIn progress: BA in Math with Stats and Data Science concentration 2026 | St. Olaf College\n\n\n\nServer | Woodhill Country Club\nMetal Fabricator | Industrial Louvers\nFood Expoditor | Maynards Restaurant"
  },
  {
    "objectID": "us_states.html",
    "href": "us_states.html",
    "title": "Geospatial Maping of Obesity In The United States",
    "section": "",
    "text": "My dataset comprises national obesity percentages categorized by state. The “Obesity” field attribute denotes the percentage of each state’s population classified as obese, based on the 2015 CDC BRFSS Survey. For this analysis, I focused on obesity percentages. The dataset I’m joining with provides latitude and longitude coordinates for each state. To merge the obesity percentages with their corresponding latitude and longitude coordinates, I performed a right join. It’s necessary to convert the state names to lowercase using the str_to_lower function because they are capitalized in the “StateObesity” tibble but are lowercase in the “us_states” tibble, ensuring accurate matching between the datasets.\n\n\n\n\n\nThe plot reveals distinct patterns in state obesity rates. Colorado stands out with the lowest average obesity rate, while Louisiana appears to have the highest. Along the West Coast, as well as in other regions, darker blue and purple hues dominate, indicating relatively lower obesity rates. Conversely, the southeastern part of the country is characterized by bright yellow shades, signifying a notably higher average obesity rate in those states."
  },
  {
    "objectID": "BirthdayParadox.html",
    "href": "BirthdayParadox.html",
    "title": "The Birthday Problem",
    "section": "",
    "text": "Background\nThe Birthday Problem The birthday paradox, often termed as the birthday problem, is a perplexing phenomenon in probability theory that challenges common intuitions regarding the likelihood of shared birthdays within a group of individuals. Contrary to what one might expect, the paradox posits that in a relatively small gathering, the probability of at least two people sharing the same birthday is surprisingly high. This paradox arises due to the counterintuitive nature of combinatorial probabilities, where the focus shifts from the likelihood of a specific individual sharing a birthday with another to the broader scenario of any two individuals sharing a birthday within the group. Through combinatorial analysis and application of the principle of inclusion-exclusion, the birthday paradox unveils that as the number of individuals increases, the probability of shared birthdays escalates at a much faster rate than anticipated, reaching a point where it becomes highly probable, even in seemingly small groups. This paradox holds significant implications in various fields, including cryptography, networking, and epidemiology, where understanding the underlying principles of probability is crucial for accurate risk assessment and decision-making.\nWhat we know We know in advance that the answer should be 23 birthdays should give us a 50% probability that two of the people in our sample will have the same birthday. We wrote this is code by taking a sample of 1 though 366 represeting the days of the year, and then taking a random sample of 23 numbers. We must incluce replace = TRUE or else R will give us distinct values.\n\nbirthdays &lt;- sample(1:366, 23, replace = TRUE) \n\n\n\nMaking Dataset\nWe make a dataset from our function so we can work with the same data for a little bit while doing out statistical analysis. The duplicated function is helpful in this case as it can find when two numbers in the same output set are the same. It will return a list of trues and falses. If two numbers are the same, the function will return a false for the first time that number appeasers but will return TRUE for the second time that number appears.\nBoolean vales in R are handy because they are read as either a 1 or a zero. That means we can use the max function to see if there was a match. If the function returns a 0 then there were no matching birthdays and if it retuns a 1 then there were matching birthdays.\n\nbirthdays &lt;- sample(1:366, 23, replace = TRUE) \n\nbirthdays |&gt;\n  duplicated()\n\n [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[13] FALSE  TRUE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE\n\nbirthdays |&gt;\n  duplicated() |&gt;\n  max()\n\n[1] 1\n\n\n\n\nUsing a for loop for mass repetition\nThe for loop iterates over the numbers 1 to 10000.\nWithin each iteration: 1. It generates a sample of 23 birthdays representing possible days in a year with replacement. 2. It checks for duplicated birthdays within the sample. 3. It assigns the result of whether duplicates were found TRUE or FALSE to the corresponding row in the match column of the matches data frame.\n\nmatches &lt;- data.frame(rep = 1:10000, match = NA)\n\nfor(i in 1:10000){\n  \nbirthdays &lt;- sample(1:366, 23, replace = TRUE) \n\nmatches$match[i] &lt;- birthdays |&gt;\n  duplicated() |&gt;\n  max() \n}\n\nmatches |&gt;\n  summarize(mean(match),\n            se = sd(match)/sqrt(10000))\n\n  mean(match)          se\n1      0.5055 0.004999947\n\n\n\n\nCreating a function\nThe function I titled birthday_problem, takes two parameters: people and iterations, representing the number of iterations to perform with the default being 10,000.\nWithin the function: 1. It initializes a data frame called matches with two columns: rep and match, with rep ranging from 1 to the specified number of iterations, and match initially filled with NA values. 2. It iterates over the specified number of iterations, again the defualt being 10,000. 3. Within each iteration - Refer to the for loop :) 4. After all iterations, it calculates the mean of the match column, standard error, and includes information about the number of people and iterations. 5. It returns a summary data frame containing the mean, standard error, number of people, and number of iterations.\n\nbirthday_problem &lt;- function(people, iterations = 10000) {\n\nmatches &lt;- data.frame(rep = 1:iterations, match = NA)\n\nfor(i in 1:iterations){\n  \nbirthdays &lt;- sample(1:366, people, replace = TRUE) \n\nmatches$match[i] &lt;- birthdays |&gt;\n  duplicated() |&gt;\n  max() \n}\n\nmatches |&gt;\n  summarize(mean1 = mean(match),\n            se = sd(match)/sqrt(iterations), \n            people = people, \n            iterations = iterations)\n}\n\n\n\nEasy way to run\nThe function, when called with people = 23, simulates the birthday problem scenario for 23 people. It generates random samples of 23 birthdays, checks for duplicates within each sample, and repeats this process for 10,000 iterations by default as explained earlier. The output will be a summary data frame with the mean probability, standard error, number of people, and number of iterations.\n\nbirthday_problem(23)\n\n   mean1          se people iterations\n1 0.5011 0.005000238     23      10000\n\n\n\n\nPreparing to graph\nThis R code iterates over the numbers from 1 to 50, calling the birthday_problem function for each number, and storing the results in a list called results_list.\nFor each iteration: 1. It calls the birthday_problem function with the current number (people_input) as the argument. 2. It appends the result. In other words, a summary data frame containing mean probability, standard error, number of people, and number of iterations to the results_list.\nAfter iterating over all numbers from 1 to 50, it combines all the summary data frames stored in results_list into a single data frame called results_birthday using do.call(rbind, results_list). This binds all the rows together into one data frame, stacking the results for each number of people on top of each other.\n\nresults_list &lt;- list()\n\nfor (people_input in seq(1, 50)) {\n  results_list[[length(results_list) + 1]] &lt;- birthday_problem(people_input)\n}\n\nresults_birthday &lt;- do.call(rbind, results_list)\n\nThe results_birthday data frame is used as the data source for the plot.\n\nggplot(results_birthday, aes(x = people, y = mean1)) +\n  geom_point(color = \"blue\", size = 2, alpha = 0.7) + \n  labs(x = \"Number of People\", y = \"Probability of Shared Birthday\",\n       title = \"Probability of Shared Birthday vs. Number of People\", \n       subtitle = \"Simulation of the Birthday Problem\", \n       caption = \"Data Source: Simulation with 10,000 Iterations\") +  \n  theme_minimal() + \n  theme(legend.position = \"none\",\n        plot.title = element_text(size = 12, face = \"bold\"),  \n        plot.subtitle = element_text(size = 12), \n        plot.caption = element_text(size = 9))"
  },
  {
    "objectID": "StringsProject.html",
    "href": "StringsProject.html",
    "title": "Strings And The New York Times",
    "section": "",
    "text": "library(RTextTools)  \n\nLoading required package: SparseM\n\n\n\nAttaching package: 'SparseM'\n\n\nThe following object is masked from 'package:base':\n\n    backsolve\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(lubridate)\nlibrary(statebins)\ndata(NYTimes)\nas_tibble(NYTimes)\n\n# A tibble: 3,104 × 5\n   Article_ID Date      Title                                 Subject Topic.Code\n        &lt;int&gt; &lt;fct&gt;     &lt;fct&gt;                                 &lt;fct&gt;        &lt;int&gt;\n 1      41246 1-Jan-96  Nation's Smaller Jails Struggle To C… Jails …         12\n 2      41257 2-Jan-96  FEDERAL IMPASSE SADDLING STATES WITH… Federa…         20\n 3      41268 3-Jan-96  Long, Costly Prelude Does Little To … Conten…         20\n 4      41279 4-Jan-96  Top Leader of the Bosnian Serbs Now … Bosnia…         19\n 5      41290 5-Jan-96  BATTLE OVER THE BUDGET: THE OVERVIEW… Battle…          1\n 6      41302 7-Jan-96  South African Democracy Stumbles on … politi…         19\n 7      41314 8-Jan-96  Among Economists, Little Fear on Def… econom…          1\n 8      41333 10-Jan-96 BATTLE OVER THE BUDGET: THE OVERVIEW… budget…          1\n 9      41344 11-Jan-96 High Court Is Cool To Census Change   census…         20\n10      41355 12-Jan-96 TURMOIL AT BARNEYS: THE DIFFICULTIES… barney…         15\n# ℹ 3,094 more rows\nFor this project, I’ve decided to utilize the NYTimes dataset to craft my narrative by analyzing textual data and addressing pertinent inquiries."
  },
  {
    "objectID": "StringsProject.html#presidents",
    "href": "StringsProject.html#presidents",
    "title": "Strings And The New York Times",
    "section": "Presidents",
    "text": "Presidents\n\nNYTpresidents &lt;- NYTimes |&gt;\n  mutate(has_bush = str_detect(Title, \"[Bb][Uu][Ss][Hh]\"),\n         has_clinton = str_detect(Title, \"[Cc][Ll][Ii][Nn][Tt][Oo][Nn]\"))\n  \n  \nNYTpresidentssummary &lt;- NYTpresidents |&gt;\n  summarise(Bush = sum(has_bush),\n            Clinton = sum(has_clinton))\n\nPrisedentsPlotData &lt;- pivot_longer(NYTpresidentssummary, cols = c(Bush, Clinton), \n                                   names_to = \"President\", \n                                   values_to = \"Count\")\n\nggplot(PrisedentsPlotData, aes(x = President, y = Count, fill = President)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"NY Times Articles mentioning Presidents Bush and Clinton\",\n       x = \"President\",\n       y = \"Count\") +\n  theme_minimal()\n\n\n\n\nWhat the code does and how I did it:\nBill Clinton and George Bush were the presidents from 1996 to 2006, which is the timeframe of the data. I created a new tibble called NYT_presidents, which will initially contain three columns: one with the original text from the “Title” column from the NY Times dataset, column “has_bush,” which will have a value of true if the string “Bush” is in the title column and NA if it does not. The “has_clinton” column works in the same way. To ensure I captured all capitalizations of the last names, I used square brackets to capture the first letter of the presidents’ last names.\n\nNYT_presidents’ summary creates new columns called “bush” and “clinton,” which count the number of true values in the NYT presidents’ data.\n“Presidents_plot_data” is NYT_presidents but pivoted longer so it can be used for graphing.\nThe final product is a bar plot showing the count of the number of times the presidents were mentioned by The New York Times.\n\nMy Story: This analysis of mentions of Presidents Bill Clinton and George Bush within The New York Times dataset holds importance. It provides a quantitative understanding of the media coverage surrounding these political figures during a pivotal period in American history. By tracking the frequency of mentions, researchers may insight into the prominence and public perception of each president over time.\nThis analysis contributes to our understanding of media bias and agenda-setting. The frequency of mentions may reflect the newspaper’s editorial priorities and the broader societal discourse surrounding these presidents’ administrations. Understanding how media coverage shapes public perception is crucial for evaluating the democratic process and the role of the media in shaping political narratives."
  },
  {
    "objectID": "StringsProject.html#money",
    "href": "StringsProject.html#money",
    "title": "Strings And The New York Times",
    "section": "Money",
    "text": "Money\n\nNYTmoney &lt;- NYTimes |&gt;\n  select(Title) |&gt;\n  filter(str_detect(Title, \"\\\\$\"))\n\n\nNYTthousand &lt;- NYTmoney |&gt;\n  mutate(thousands = as.numeric(gsub(\",\", \"\", str_extract(Title, \"\\\\d{1,3},\\\\d{3}\"))))\n\n\nNYTmillion &lt;- NYTmoney |&gt;\n  mutate(millionsnumber = str_extract(Title, \"[Mm][Ii][Ll][Ll][Ii][Oo][Nn]\")) |&gt;\n  mutate(millions = ifelse(!is.na(millionsnumber), as.numeric(str_extract(Title, \"\\\\d+\\\\.?\\\\d*\")), NA)) |&gt;\n  select(Title, millions)\n\n\nNYTbillion &lt;- NYTmoney |&gt;\n  mutate(billionsnumber = str_extract(Title, \"[Bb][Ii][Ll][Ll][Ii][Oo][Nn]\")) |&gt;\n  mutate(billions = ifelse(!is.na(billionsnumber), as.numeric(str_extract(Title, \"\\\\d+\\\\.?\\\\d*\")), NA)) |&gt;\n  select(Title, billions)\n\n\nNYTtrillion &lt;- NYTmoney |&gt;\n  mutate(trillionsnumber = str_extract(Title, \"[Tt]rillion\")) |&gt;\n  mutate(trillions = ifelse(!is.na(trillionsnumber), as.numeric(str_extract(Title, \"\\\\d+\\\\.?\\\\d*\")), NA)) |&gt;\n  select(Title, trillions)\n\n\nNYT_combined &lt;- left_join(NYTmillion, NYTbillion, by = \"Title\")\nNYT_combined &lt;- left_join(NYT_combined, NYTtrillion, by = \"Title\")\nNYT_combined &lt;- left_join(NYT_combined, NYTthousand, by = \"Title\")\n\nprint(NYT_combined)\n\n                                                                                          Title\n1                          Milnerton Journal; This $40 Crank-Up Radio Lets Rural Africa Tune In\n2                                           RUSSIA AND I.M.F. AGREE ON A LOAN FOR $10.2 BILLION\n3                                           2 Governors Back $130 Million Plan To Deepen Harbor\n4         GIULIANI'S BUDGET PLAN: THE OVERVIEW; Giuliani Offers an Austere $32.7 Billion Budget\n5                                Mayor and Council Hold Strings For $276 Million Schools Pledge\n6                                        CLINTON SIGNS BILL FOR $256.6 BILLION FOR ARMED FORCES\n7                                 U.S. to Settle for $4.8 Million In Suits on Radiation Testing\n8                                         A Co-op Must Pay $640,000 For Denying Sublet to Black\n9                                           AUDIT OF MEDICARE FINDS $23 BILLION IN OVERPAYMENTS\n10                                    ITT Accepts $9.8 Billion Bid, Forming Biggest Hotel Chain\n11      BANKING'S CONSOLIDATION: THE DEAL; $17.1 BILLION DEAL FOR BANK CREATES EAST COAST GIANT\n12      CRISIS IN SOUTH KOREA: THE BAILOUT; PACKAGE OF LOANS WORTH $55 BILLION IS SET FOR KOREA\n13                                                30 Firms to Pay $900 Million In Investor Suit\n14                                            A $12 Billion Carrot for Prudential Policyholders\n15                                          JAPAN ANNOUNCES $195 BILLION PLAN TO REVIVE ECONOMY\n16                                         REPUBLICANS' GOAL IS $1 MILLION EACH FROM TOP DONORS\n17                                Gore Proposal Would Set Aside $115 Billion for Education Fund\n18                                          SENATE APPROVES $1 BILLION TO AID COLOMBIA MILITARY\n19                                         DEUTSCHE TELEKOM TO PAY $50 BILLION FOR U.S. COMPANY\n20                                 Chevron Agrees to Buy Texaco For Stock Valued at $36 Billion\n21                                                          Surplus Estimate Hits $5.6 Trillion\n22 The President's Budget: The Proposal; President Unveils $1.96 Trillion Plan That Trims Taxes\n23                               A Rival Is Offering $44.5 Billion For AT&T's Cable TV Business\n24                     The Media Business; Publisher Will Pay Clinton Over $10 Million for Book\n25                                                    Firestone Set to Pay $7.5 Million in Suit\n26                                       LIBYA IS OFFERING TO PAY $2.7 BILLION FOR PAN AM BLAST\n27                                                     Edison Schools Gets $40 Million in Loans\n28                                               Bush Aide Sees Deficit in 2003 Of $200 Billion\n29                                              House Approves 10-Year Tax Cut For $550 Billion\n30                                MCI Agrees to Pay $500 Million In FraudCase, S.E.C.'s Largest\n31                           TECHNOLOGY; \\nMICROSOFT TO PAY AOL $750 MILLION; END TO 'LONG WAR'\n32                                           $58 BILLION DEAL TO UNITE 2 GIANTS OF U.S. BANKING\n33                                             For Iraqis in Harm's Way, $5,000 and 'I'm Sorry'\n34                                            I.B.M. EMPLOYEES GET $320 MILLION IN PENSION SUIT\n35                                             Con Ed to Pay $7.2 Million in Electrocution Case\n36                             New White House Estimate Lifts Drug Benefit Cost to $720 Billion\n37                                  Harvard Will Spend $50 Million To Make Faculty More Diverse\n38                                    Somalis Brave a Sea of Perils For $50-a-Month Jobs Abroad\n39                                               Telecom Giants In Europe Plan $30 Billion Deal\n   millions billions trillions thousands\n1        NA       NA        NA        NA\n2        NA     10.2        NA        NA\n3       2.0       NA        NA        NA\n4        NA     32.7        NA        NA\n5     276.0       NA        NA        NA\n6        NA    256.6        NA        NA\n7       4.8       NA        NA        NA\n8        NA       NA        NA    640000\n9        NA     23.0        NA        NA\n10       NA      9.8        NA        NA\n11       NA     17.1        NA        NA\n12       NA     55.0        NA        NA\n13     30.0       NA        NA        NA\n14       NA     12.0        NA        NA\n15       NA    195.0        NA        NA\n16      1.0       NA        NA        NA\n17       NA    115.0        NA        NA\n18       NA      1.0        NA        NA\n19       NA     50.0        NA        NA\n20       NA     36.0        NA        NA\n21       NA       NA      5.60        NA\n22       NA       NA      1.96        NA\n23       NA     44.5        NA        NA\n24     10.0       NA        NA        NA\n25      7.5       NA        NA        NA\n26       NA      2.7        NA        NA\n27     40.0       NA        NA        NA\n28       NA   2003.0        NA        NA\n29       NA     10.0        NA        NA\n30    500.0       NA        NA        NA\n31    750.0       NA        NA        NA\n32       NA     58.0        NA        NA\n33       NA       NA        NA      5000\n34    320.0       NA        NA        NA\n35      7.2       NA        NA        NA\n36       NA    720.0        NA        NA\n37     50.0       NA        NA        NA\n38       NA       NA        NA        NA\n39       NA     30.0        NA        NA\n\n\nNYTmoney: - This chunk selects rows from the dataset NYTimes where the title contains a dollar sign (‘$’).\nNYTthousand: - This chunk takes the subset of data identified as containing monetary values in the thousands. - It extracts the numeric values from the titles that are formatted with thousands (with commas), converting them into numeric values.\nNYTmillion: - This chunk identifies rows with monetary values expressed in millions. - It extracts both the word ‘million’ and the numeric values associated with it, converting the numeric values into numeric format.\nNYTbillion: - Similar to the previous chunk, this one focuses on monetary values expressed in billions. - It extracts both the word ‘billion’ and the associated numeric values, converting them into numeric format.\nNYTtrillion: - Similar to the previous chunks, this one focuses on monetary values expressed in trillions. - It extracts both the word ‘trillion’ and the associated numeric values, converting them into numeric format.\nNYT_combined: - This chunk joins the dataframes created in the previous steps (NYTmillion, NYTbillion, NYTtrillion, NYTthousand) based on the common column ‘Title’. - It combines all the extracted monetary values into a single dataframe, NYT_combined, where each row corresponds to a title from the New York Times dataset, with columns for millions, billions, trillions, and thousands as applicable.\nMy Story:\nThe dataset from The New York Times provides insights into monetary discussions within its articles. Through filtering, specific monetary values, spanning thousands to trillions, are extracted, representing diverse economic narratives such as corporate deals, budget allocations, and economic forecasts. These figures offer valuable context, highlighting trends and developments across sectors.\nAs the analysis progresses, the dataset combines these monetary categories, offering a comprehensive view of financial discussions over time. This merging process enables a nuanced understanding of hwo common and the distribution of monetary references within The New York Times articles.\nThis exploration of monetary mentions serves as a valuable resource for researchers, journalists, and policymakers, offering a quantifiable look on economic discourse. The easiness of tracking financial trends and provides insight into the narratives shaping public perception and policy decisions."
  },
  {
    "objectID": "StringsProject.html#united-states",
    "href": "StringsProject.html#united-states",
    "title": "Strings And The New York Times",
    "section": "United States",
    "text": "United States\n\nstates &lt;- as.tibble(state.name)\n\nWarning: `as.tibble()` was deprecated in tibble 2.0.0.\nℹ Please use `as_tibble()` instead.\nℹ The signature and semantics have changed, see `?as_tibble`.\n\nstates &lt;- rename(states, state_name = value)\n\n\nextract_state &lt;- function(Title) {\n  state_match &lt;- str_extract(Title, paste(str_to_lower(state.name), collapse = \"|\"))\n  if (is.na(state_match)) {\n    return(NA)\n  } else {\n    return(state_match)\n  }\n}\n\nNYTimes$Title &lt;- str_to_lower(NYTimes$Title)\n\nNYTstates &lt;- tibble(\n  Title = NYTimes$Title,\n  State = sapply(NYTimes$Title, extract_state))\n\nNYTstates &lt;- NYTstates |&gt;\n  filter(!is.na(State))\n\nprint(NYTstates)\n\n# A tibble: 167 × 2\n   Title                                                                   State\n   &lt;chr&gt;                                                                   &lt;chr&gt;\n 1 despite deep grass roots in iowa, gramm struggles to catch forbes       iowa \n 2 moderating path, rowland aims at healing of connecticut cities          conn…\n 3 high water in oregon                                                    oreg…\n 4 politics: the issues; south carolina is a crossroads for the g.o.p.     sout…\n 5 politics: changing direction; dole easily beats buchanan to win in sou… sout…\n 6 the race for congress: texas' 14th district; under fire, a g.o.p. conv… texas\n 7 new york council to ask voters to postpone limits on its terms          new …\n 8 schools head urges abolishing tenure for new york principals            new …\n 9 california's governor joins g.o.p. abortion-plank foes                  cali…\n10 a new kansas senator                                                    kans…\n# ℹ 157 more rows\n\n\n\n# Plotting the data\nggplot(NYTstates, aes(x = State, color = State)) +\n  geom_bar(show.legend = FALSE) +\n  labs(\n    title = \"Number of Articles by State\",\n    x = \"State\",\n    y = \"Number of Articles\"\n  ) +\n  theme_minimal()\n\n\n\n\nCreating a tibble of state names:\n- The first chunk initializes a tibble named “states” containing the names of the states in the United States.\n- It then renames the column containing state names to “state_name”.\nDefining a function to extract state names from article titles:\n- The second chunk defines a function called “extract_state”, which takes a title as input.\n- Within the function, it searches for state names in the title using lowercase versions of state names.\n- If a state name is found, it returns the matched state, otherwise, it returns NA.\nApplying the function to the NYTimes dataset:\n- The NYTimes dataset’s titles are converted to lowercase.\n- A new tibble named “NYTstates” is created, containing the titles and the corresponding state names extracted using the “extract_state” function.\n- Rows with NA values in the “State” column are filtered out.\nPlotting the data:\n- Finally, the code generates a bar plot using ggplot, depicting the number of articles by state.\nMy Story: This code offers an oppourunity for exploring geographic trends in media through The New York Times. By extracting mentions of U.S. states from article titles, I provided insight into which regions garner the most attention within the NYT. This information could be useful for journalists, helping them identify areas of interest or underserved regions warranting more coverage.\nResearchers could also use this data to analyze how media attention correlates with various factors such as population density, political significance, or socioeconomic status across different states. Politicians and policymakers may also find utility in understanding which states receive the most media coverage and tailoring their messaging or policies accordingly."
  },
  {
    "objectID": "Projects.html",
    "href": "Projects.html",
    "title": "Understanding Medications: Uncovering Side Effects",
    "section": "",
    "text": "This is Understanding Medications: Uncovering Side Effects.\n\nThe past year and a half I have been studying the essential skills in R such as Data visualization, tidying, transformation. Over this time I have practiced my coding skills using joins, factors, strings and other workflow basics. In the fall of 2023 Jackson Marsh and I conducted a study on the side effects of popular prescription drugs and the cautions of drug interactions."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Courses at St. Olaf College",
    "section": "",
    "text": "I have taken the following MSCS courses during my time at St. Olaf College\n\nCalculus 2:\n\nTechniques of integration including substitution, integration by parts, and partial fractions.\nApplications of integration such as finding areas, volumes, and arc lengths.\nSequences and series including convergence tests and Taylor series.\n\nCalculus 3:\n\nMultivariable calculus including partial derivatives, multiple integrals, and line integrals.\nVector calculus concepts like gradients, divergence, and curl.\nApplications such as optimization problems and parametric surfaces.\n\nProbability Theory:\n\nFundamentals of probability including probability spaces, random variables, and probability distributions.\nProbability rules like Bayes’ theorem and the law of total probability.\nBasic concepts of statistics including expected value, variance, and probability distributions.\n\nLinear Algebra:\n\nVector spaces, subspaces, and linear transformations.\nMatrix operations including addition, multiplication, and inverses.\nEigenvalues and eigenvectors, diagonalization, and applications such as solving systems of linear equations.\n\nData Science 1:\n\nIntroduction to R programming language and RStudio environment for data analysis.\nPrinciples of data tidying and manipulation using tools like the tidyverse package.\nBuilding personal data analysis projects from data acquisition and cleaning to visualization and interpretation.\n\nData Science 2:\n\nIn progress\n\nStatistics 1:\n\nDescriptive statistics including measures of central tendency and dispersion.\nProbability distributions and their properties.\nStatistical inference including hypothesis testing and confidence intervals."
  }
]